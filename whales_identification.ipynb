{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Whales identification from their tails - Kaggle contest"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Dependencies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "import keras\n",
    "import numpy as np\n",
    "import glob\n",
    "import pandas as pd\n",
    "import os\n",
    "import shutil"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Dataset reading"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading dataset/train.csv\n",
      "#7869/9850\r"
     ]
    }
   ],
   "source": [
    "class Dataset:\n",
    "    \"\"\"\n",
    "    Manage dataset loading\n",
    "    \n",
    "    :param dataset_path: str, path to the dataset folder\n",
    "    \"\"\"\n",
    "    \n",
    "    def __init__(self, dataset_path):\n",
    "        \n",
    "        # Build and store dataset paths\n",
    "        self.dataset_path_train = dataset_path + \"/train\"\n",
    "        self.dataset_path_test = dataset_path + \"/test\"\n",
    "        \n",
    "        # Build train.csv path\n",
    "        self.dataset_path_train_label = dataset_path + \"/train.csv\"\n",
    "        \n",
    "        # Generate pandas dataframe of whales id <-> file matching\n",
    "        self.dataset_train_label = self.get_train_label()\n",
    "        \n",
    "        ## Get pictures paths\n",
    "#         self.les_im_path_train = self.get_im_path(self.dataset_path_train + \"/*.jpg\")\n",
    "#         self.les_im_path_test = self.get_im_path(self.dataset_path_test + \"/*.jpg\")\n",
    "        \n",
    "    def get_im_path(self, dataset_path):\n",
    "        \"\"\"\n",
    "        Get pictures path under the given folder path\n",
    "        :param dataset_path: str, path to the dataset folder\n",
    "        \n",
    "        :output les_im_path: list of string, .jpg picture paths under the dataset_path folder\n",
    "        \"\"\"\n",
    "        print(\"Getting images path from\", dataset_path)\n",
    "        les_im_path = glob.glob(dataset_path)\n",
    "        les_im_path.sort()\n",
    "        return les_im_path\n",
    "    \n",
    "    def get_train_label(self):\n",
    "        \"\"\"\n",
    "        Load the train dataset annotation using pandas\n",
    "        \n",
    "        :return train_label: pandas dataframe, whales id <-> files matching\n",
    "        \"\"\"\n",
    "        print(\"Loading\", self.dataset_path_train_label)\n",
    "        return pd.read_csv(self.dataset_path_train_label)\n",
    "    \n",
    "    \n",
    "    def create_folder_is_needed(self, folder_path):\n",
    "        \"\"\"\n",
    "        Create a folder if it doesn't alreadt exist\n",
    "        :param folder_path: str\n",
    "        \"\"\"\n",
    "        if not os.path.isdir(folder_path):\n",
    "            os.mkdir(folder_path)\n",
    "    \n",
    "    def split_in_classes_folders(self, root_classes_folder, pass_new_whale=True):\n",
    "        \"\"\"\n",
    "        Split the dataset into classes folders\n",
    "        :param root_classes_folder:\n",
    "        :param pass_new_whale: boolean, set to true if not considering new_whale id\n",
    "        \n",
    "        OUTPUT:\n",
    "            pictures sort by whale id into subfolders of the root_classes_folder\n",
    "        \"\"\"\n",
    "        # Create the root folder if needed\n",
    "        self.create_folder_is_needed(root_classes_folder)\n",
    "        \n",
    "        # If passing new whales, should remove previous folder\n",
    "        new_whale_folder_path = \"/\".join([root_classes_folder, \"new_whale\"])\n",
    "        if pass_new_whale and os.path.isdir(new_whale_folder_path):\n",
    "            print(\"Removing new_whale folder\")\n",
    "            shutil.rmtree(new_whale_folder_path)\n",
    "        \n",
    "        files_number = len(self.dataset_train_label)\n",
    "        \n",
    "        # Sorting the images\n",
    "        for index, row in self.dataset_train_label.iterrows():\n",
    "            print(\"#\" + str(index + 1) + \"/\" + str(files_number), end=\"\\r\")\n",
    "            whale_file_name = row['Image']\n",
    "            whale_id = row['Id']\n",
    "            if pass_new_whale and whale_id == \"new_whale\":\n",
    "                continue\n",
    "            \n",
    "            self.create_folder_is_needed(\"/\".join([root_classes_folder, whale_id]))\n",
    "            shutil.copy(\n",
    "                \"/\".join([self.dataset_path_train, whale_file_name]), \n",
    "                \"/\".join([root_classes_folder, whale_id, whale_file_name])\n",
    "            )\n",
    "        print(\" - Done\")\n",
    "            \n",
    "            \n",
    "# Create the dataset object\n",
    "dataset = Dataset(\"dataset\")\n",
    "# Split the dataset into the train_classes folder\n",
    "dataset.split_in_classes_folders(\"dataset/train_classes\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<__main__.Dataset at 0x7efe1686cf28>"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
