{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Whales identification from their tails - Kaggle contest"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Dependencies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import glob\n",
    "import pandas as pd\n",
    "import os\n",
    "import shutil\n",
    "import random\n",
    "import matplotlib.pyplot as plt\n",
    "import cv2\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Dataset reading"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading dataset/train.csv\n",
      "Removing previous spliting\n",
      "Sorting 25361 images into dataset/train_classes\n",
      "#133/25361\r"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-115-2c83f6580dfd>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m    196\u001b[0m \u001b[0mdataset\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mDataset\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"dataset\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    197\u001b[0m \u001b[0;31m# Split the dataset into the train_classes folder\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 198\u001b[0;31m \u001b[0mdataset\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msplit_in_classes_folders\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"dataset/train_classes\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mremove_new_whale\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mremove_old\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain_dev_ratio\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0.2\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcrop\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-115-2c83f6580dfd>\u001b[0m in \u001b[0;36msplit_in_classes_folders\u001b[0;34m(self, root_classes_folder, remove_new_whale, remove_old, train_dev_ratio, crop)\u001b[0m\n\u001b[1;32m    112\u001b[0m             \u001b[0mtarget_path\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m\"/\"\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjoin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0msub_dataset_path\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mwhale_id\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mwhale_file_name\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    113\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mcrop\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 114\u001b[0;31m                 \u001b[0mcv2\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mimwrite\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtarget_path\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_convex_masked_tail\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0morig_path\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    115\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    116\u001b[0m                 \u001b[0mshutil\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcopy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0morig_path\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget_path\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-115-2c83f6580dfd>\u001b[0m in \u001b[0;36mget_convex_masked_tail\u001b[0;34m(self, im_path, disp)\u001b[0m\n\u001b[1;32m    182\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mx\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcrop\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    183\u001b[0m             \u001b[0;32mfor\u001b[0m \u001b[0my\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcrop\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 184\u001b[0;31m                 \u001b[0;32mif\u001b[0m \u001b[0mcv2\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpointPolygonTest\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcnt_hull\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    185\u001b[0m                     \u001b[0mcrop\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mim_gray\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    186\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "class Dataset:\n",
    "    \"\"\"\n",
    "    Manage dataset loading\n",
    "    \n",
    "    :param dataset_path: str, path to the dataset folder\n",
    "    \"\"\"\n",
    "    \n",
    "    def __init__(self, dataset_path):\n",
    "        \n",
    "        # Build and store dataset paths\n",
    "        self.dataset_path_train = dataset_path + \"/train\"\n",
    "        self.dataset_path_test = dataset_path + \"/test\"\n",
    "        \n",
    "        # Build train.csv path\n",
    "        self.dataset_path_train_label = dataset_path + \"/train.csv\"\n",
    "        \n",
    "        # Generate pandas dataframe of whales id <-> file matching\n",
    "        self.dataset_train_label = self.get_train_label()\n",
    "        \n",
    "        ## Get pictures paths\n",
    "#         self.les_im_path_train = self.get_im_path(self.dataset_path_train + \"/*.jpg\")\n",
    "#         self.les_im_path_test = self.get_im_path(self.dataset_path_test + \"/*.jpg\")\n",
    "        \n",
    "    def get_im_path(self, dataset_path):\n",
    "        \"\"\"\n",
    "        Get pictures path under the given folder path\n",
    "        :param dataset_path: str, path to the dataset folder\n",
    "        \n",
    "        :output les_im_path: list of string, .jpg picture paths under the dataset_path folder\n",
    "        \"\"\"\n",
    "        print(\"Getting images path from\", dataset_path)\n",
    "        les_im_path = glob.glob(dataset_path)\n",
    "        les_im_path.sort()\n",
    "        return les_im_path\n",
    "    \n",
    "    def get_train_label(self):\n",
    "        \"\"\"\n",
    "        Load the train dataset annotation using pandas\n",
    "        \n",
    "        :return train_label: pandas dataframe, whales id <-> files matching\n",
    "        \"\"\"\n",
    "        print(\"Loading\", self.dataset_path_train_label)\n",
    "        return pd.read_csv(self.dataset_path_train_label)\n",
    "    \n",
    "    \n",
    "    def create_folder_is_needed(self, folder_path):\n",
    "        \"\"\"\n",
    "        Create a folder if it doesn't alreadt exist\n",
    "        :param folder_path: str\n",
    "        \"\"\"\n",
    "        if not os.path.isdir(folder_path):\n",
    "            os.mkdir(folder_path)\n",
    "    \n",
    "    def split_in_classes_folders(self, root_classes_folder, remove_new_whale=True, remove_old=True, train_dev_ratio=0.2, crop=False):\n",
    "        \"\"\"\n",
    "        Split the dataset into classes folders\n",
    "        :param root_classes_folder:\n",
    "        :param remove_new_whale: boolean, set to true if not considering new_whale id\n",
    "        \n",
    "        OUTPUT:\n",
    "            pictures sort by whale id into subfolders of the root_classes_folder\n",
    "        \"\"\"\n",
    "        \n",
    "        if remove_old and os.path.isdir(root_classes_folder):\n",
    "            print(\"Removing previous spliting\")\n",
    "            shutil.rmtree(root_classes_folder)\n",
    "        \n",
    "        sub_dataset_train_path = \"/\".join([root_classes_folder, \"train\"])\n",
    "        sub_dataset_dev_path = \"/\".join([root_classes_folder, \"dev\"])\n",
    "        \n",
    "        # Create the folders if needed\n",
    "        self.create_folder_is_needed(root_classes_folder)\n",
    "        self.create_folder_is_needed(sub_dataset_train_path)\n",
    "        self.create_folder_is_needed(sub_dataset_dev_path)\n",
    "        \n",
    "        # If passing new whales, should remove previous folder\n",
    "        if remove_new_whale and os.path.isdir(root_classes_folder):\n",
    "            print(\"Removing new_whale folder\")\n",
    "            train_new_whale = \"/\".join([sub_dataset_train_path, \"new_whale\"])\n",
    "            if os.path.isdir(train_new_whale):\n",
    "                shutil.rmtree(train_new_whale)\n",
    "            dev_new_whale = \"/\".join([sub_dataset_dev_path, \"new_whale\"])\n",
    "            if os.path.isdir(dev_new_whale):\n",
    "                shutil.rmtree(dev_new_whale)\n",
    "        \n",
    "        # Sorting the images\n",
    "        files_number = len(self.dataset_train_label)\n",
    "        print(\"Sorting\", files_number, \"images into\", root_classes_folder)\n",
    "        \n",
    "        for index, row in self.dataset_train_label.iterrows():\n",
    "            print(\"#\" + str(index + 1) + \"/\" + str(files_number), end=\"\\r\")\n",
    "            whale_file_name = row['Image']\n",
    "            whale_id = row['Id']\n",
    "            if remove_new_whale and whale_id == \"new_whale\":\n",
    "                continue\n",
    "            \n",
    "            ## Choose if storing in train of dev dataset\n",
    "            if len(glob.glob(\"/\".join([sub_dataset_train_path, whale_id]))):\n",
    "                # If 80% uniform and dev aleady exist\n",
    "                if random.uniform(0, 1) >= train_dev_ratio and len(glob.glob(\"/\".join([sub_dataset_dev_path, whale_id]))):\n",
    "                    # We store in train dataset\n",
    "                    sub_dataset_path = sub_dataset_train_path\n",
    "                else:\n",
    "                    # We store in dev dataset\n",
    "                    sub_dataset_path = sub_dataset_dev_path\n",
    "            else:\n",
    "                sub_dataset_path = sub_dataset_train_path\n",
    "            \n",
    "            # Create folder and generate path name\n",
    "            self.create_folder_is_needed(\"/\".join([sub_dataset_path, whale_id]))\n",
    "            orig_path = \"/\".join([self.dataset_path_train, whale_file_name])\n",
    "            target_path = \"/\".join([sub_dataset_path, whale_id, whale_file_name])\n",
    "            if crop:\n",
    "                cv2.imwrite(target_path, self.get_convex_masked_tail(orig_path))\n",
    "            else:\n",
    "                shutil.copy(orig_path, target_path)\n",
    "                \n",
    "        print(\"Done\" + \" \"*20)\n",
    "        \n",
    "        ## Removing folder that doesn't have a dev equivalent\n",
    "        for train_path in glob.glob(sub_dataset_train_path + \"/*/\"):\n",
    "            in_train_id = train_path.split(\"/\")[-2]\n",
    "            equivalent_dev_id_path = \"/\".join([sub_dataset_dev_path, in_train_id])\n",
    "            if not os.path.isdir(equivalent_dev_id_path):\n",
    "                shutil.rmtree(train_path)\n",
    "    \n",
    "    def disp_image(self, im, gray=False):\n",
    "        \"\"\"\n",
    "        Display an image in a plt plot\n",
    "        :param im: image, numpy array format, used by cv2\n",
    "        \"\"\"\n",
    "        \n",
    "        if gray:\n",
    "            imgplot = plt.imshow(im, cmap='gray')\n",
    "        else:\n",
    "            imgplot = plt.imshow(im)\n",
    "        plt.show()\n",
    "\n",
    "        \n",
    "    def get_convex_masked_tail(self, im_path, disp=False):\n",
    "        \"\"\"\n",
    "        Return the image of the tail-convex-crop\n",
    "        :param im_path: str, path to the image\n",
    "        :param disp: bool, set to true to display\n",
    "        \"\"\"\n",
    "        \n",
    "        # Load image and resize witout changing ratio\n",
    "        im = cv2.imread(im_path)\n",
    "        height, width = im.shape[:2]\n",
    "        new_width = 500\n",
    "        new_height = new_width*height//width\n",
    "        im = cv2.resize(im,(new_width, new_height), interpolation = cv2.INTER_CUBIC)\n",
    "\n",
    "        # Change to gray and apply both gaussian and threshold filter\n",
    "        im_gray = cv2.cvtColor(im, cv2.COLOR_BGR2GRAY)\n",
    "        blurred_im = cv2.GaussianBlur(im_gray, (5, 5), 0)\n",
    "        aver = np.average(im_gray)\n",
    "        ret,thresh = cv2.threshold(blurred_im, int(aver*0.8), 255, cv2.THRESH_BINARY_INV)\n",
    "        blurred_im = cv2.GaussianBlur(thresh, (5, 5), 0)\n",
    "\n",
    "        # Compute contours\n",
    "        contours, _ = cv2.findContours(thresh, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)\n",
    "\n",
    "        areas = []\n",
    "        for cnt in contours:\n",
    "            areas.append(cv2.contourArea(cnt))\n",
    "\n",
    "        # get bigger area and store its contour\n",
    "        cnt = contours[np.argmax(areas)]\n",
    "\n",
    "        # Get convex contour\n",
    "        cnt_hull = cv2.convexHull(cnt)\n",
    "\n",
    "        # Check if point is in contour. If yes store it in \n",
    "        # - - - - -> Y\n",
    "        #|\n",
    "        #|\n",
    "        #v\n",
    "        #\n",
    "        #X\n",
    "        crop = np.zeros_like(im)\n",
    "        for x in range(crop.shape[1]):\n",
    "            for y in range(crop.shape[0]):\n",
    "                if cv2.pointPolygonTest(cnt_hull, (x, y), False) == 1:\n",
    "                    crop[y, x] = im_gray[y, x]\n",
    "\n",
    "        if disp:\n",
    "            print(area)\n",
    "            self.disp_image(crop, gray=True)\n",
    "            im2 = cv2.drawContours(im.copy(), cnt_hull, -1, (255,0,0), 4)\n",
    "            self.disp_image(im2)\n",
    "\n",
    "        return crop\n",
    "\n",
    "# Create the dataset object\n",
    "dataset = Dataset(\"dataset\")\n",
    "# Split the dataset into the train_classes folder\n",
    "dataset.split_in_classes_folders(\"dataset/train_classes\", remove_new_whale=False, remove_old=True, train_dev_ratio=0.2, crop=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Tails cropping"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
